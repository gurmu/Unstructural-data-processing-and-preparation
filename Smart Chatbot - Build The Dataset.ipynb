{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1><center> Unstructural data processing and preparation</center></h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson Goals\n",
    "<div text-align:justify>we are gonna process full unstructural data that i scrab it from three different websites and save it as cvs file.So in this lesson we will Processing unstructured data means extracting structure from it.</div>\n",
    "\n",
    " \n",
    "\n",
    "# Prerequests \n",
    "  1. install NLTK\n",
    "  2. Install Anaconda\n",
    "  \n",
    "  NB:make sure Jupyter Notebook running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_path = 'C:/Users/agurm/OneDrive/Desktop/Sarcasticbot/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First dataset\n",
    "The Wordball Joke Dataset, link.\n",
    "\n",
    "This dataset consists of three files, namely:\n",
    "\n",
    "qajokes1.1.2.csv: with 75,114 pairs.\n",
    "t_lightbulbs.csv: with 2,640 pairs.\n",
    "t_nosubject.csv: with 32,120 pairs.\n",
    "However, I'm not going to incorporate t_lightbulbs.csv in my dataset because I don't want that many examples of one topic. Besides, all the examples are similar in structure (they all start with how many).\n",
    "\n",
    "Read the data files into pandas dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordball_qajokes = pd.read_csv(files_path + 'qajokes1.1.2.csv', usecols=['Question', 'Answer'])\n",
    "wordball_nosubj = pd.read_csv(files_path + 't_nosubject.csv', usecols=['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75114\n",
      "32120\n"
     ]
    }
   ],
   "source": [
    "print(len(wordball_qajokes))\n",
    "print(len(wordball_nosubj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why was the Ethiopian baby crying?</td>\n",
       "      <td>He was having a mid-life crisis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0       What's the best anti diarrheal prescription?   \n",
       "1  What do you call a person who is outside a doo...   \n",
       "2  Which Star Trek character is a member of the m...   \n",
       "3  What's the difference between a bullet and a h...   \n",
       "4                 Why was the Ethiopian baby crying?   \n",
       "\n",
       "                            Answer  \n",
       "0                 Mycheexarphlexin  \n",
       "1                             Matt  \n",
       "2               Jean-Luc Pickacard  \n",
       "3    A bullet doesn't miss Harambe  \n",
       "4  He was having a mid-life crisis  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordball_qajokes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did you hear about the Native American man tha...</td>\n",
       "      <td>He nearly drown in his own tea pee.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Did you hear about the oyster who went to the ...</td>\n",
       "      <td>He pulled a muscle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shall I tell you the joke about the kidnappers?</td>\n",
       "      <td>I'd better not. You might get carried away.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Do you like fish sticks?</td>\n",
       "      <td>Well then, you're a gay fish.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Want to hear a joke about UDP?</td>\n",
       "      <td>Never mind. you won't get it, and I won't care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Did you hear about the Native American man tha...   \n",
       "1  Did you hear about the oyster who went to the ...   \n",
       "2    Shall I tell you the joke about the kidnappers?   \n",
       "3                           Do you like fish sticks?   \n",
       "4                     Want to hear a joke about UDP?   \n",
       "\n",
       "                                           Answer  \n",
       "0             He nearly drown in his own tea pee.  \n",
       "1                             He pulled a muscle   \n",
       "2     I'd better not. You might get carried away.  \n",
       "3                  Well then, you're a gay fish.   \n",
       "4  Never mind. you won't get it, and I won't care  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordball_nosubj.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why was the Ethiopian baby crying?</td>\n",
       "      <td>He was having a mid-life crisis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0       What's the best anti diarrheal prescription?   \n",
       "1  What do you call a person who is outside a doo...   \n",
       "2  Which Star Trek character is a member of the m...   \n",
       "3  What's the difference between a bullet and a h...   \n",
       "4                 Why was the Ethiopian baby crying?   \n",
       "\n",
       "                            Answer  \n",
       "0                 Mycheexarphlexin  \n",
       "1                             Matt  \n",
       "2               Jean-Luc Pickacard  \n",
       "3    A bullet doesn't miss Harambe  \n",
       "4  He was having a mid-life crisis  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordball = pd.concat([wordball_qajokes, wordball_nosubj], ignore_index=True)\n",
    "wordball.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question-answer pairs in the Wordball dataset: 107234\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of question-answer pairs in the Wordball dataset: {len(wordball)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "It turns out that not all cells are of type string. So, we can just apply the str function to make sure that all of them are of the same desired type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordball = wordball.applymap(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the characters used in this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinct_chars(data, cols):\n",
    "    \"\"\"\n",
    "    This method takes in a pandas dataframe and prints all distinct characters.\n",
    "    data: a pandas dataframe.\n",
    "    cols: a Python list, representing names of columns for questions and answers. First item of the list should be the name \n",
    "    of the questions column and the second item should be the name of the column corresponding to answers.\n",
    "    \"\"\"\n",
    "    \n",
    "    if cols is None:\n",
    "        cols = list(data.columns)\n",
    "    \n",
    "    # join all questions into one string\n",
    "    questions = ' '.join(data[cols[0]])\n",
    "    # join all answers into one string\n",
    "    answers = ' '.join(data[cols[1]])\n",
    "    \n",
    "    # get distinct characters used in the data (all questions and answers)\n",
    "    dis_chars = set(questions+answers)\n",
    "    \n",
    "    # print the distinct characters that are used in the data\n",
    "    print(f\"Number of distinct characters used in the dataset: {len(dis_chars)}\")\n",
    "    # print(dis_chars)    \n",
    "    dis_chars = list(dis_chars)\n",
    "    \n",
    "    # Now let's print those characters in an organized way\n",
    "    digits = [char for char in dis_chars if char.isdigit()]\n",
    "    alphabets = [char for char in dis_chars if char.isalpha()]\n",
    "    special = [char for char in dis_chars if not (char.isdigit() | char.isalpha())]\n",
    "    # sort them to make them easier to read\n",
    "    digits = sorted(digits)\n",
    "    alphabets = sorted(alphabets)\n",
    "    special = sorted(special)\n",
    "    \n",
    "    print(f\"Digits: {digits}\")\n",
    "    print(f\"Alphabets: {alphabets}\")\n",
    "    print(f\"Special characters: {special}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters used in the dataset: 120\n",
      "Digits: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Alphabets: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '√ü', '√®', '√©', '√±', '√≥', '√∂', '√º']\n",
      "Special characters: [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '\\xa0', '¬°', '¬§', '¬´', '¬∞', '¬ª', '¬ø', '\\u200b', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¶', '‚Ñ¢', '\\ufeff', 'üé∫']\n"
     ]
    }
   ],
   "source": [
    "distinct_chars(wordball, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function replaces some characters with others, removes unwanted characters and gets rid of extra whitespaces from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    This method takes a string, applies different text preprocessing (characters replacement, removal of unwanted characters, \n",
    "    removal of extra whitespaces) operations and returns a string.\n",
    "    text: a string.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # REPLACEMENT\n",
    "    # replace \" with ' (because they basically mean the same thing)\n",
    "    # text = text.replace('\\\"','\\'')\n",
    "    text = re.sub('\\\"', '\\'', text)\n",
    "    # replace ‚Äú and ‚Äù with '\n",
    "    # text = text.replace(\"‚Äú\",'\\'').replace(\"‚Äù\",'\\'')\n",
    "    text = re.sub(\"‚Äú\", '\\'', text)\n",
    "    text = re.sub(\"‚Äù\", '\\'', text)\n",
    "    # replace ‚Äô with '\n",
    "    # text = text.replace('‚Äô','\\'')\n",
    "    text = re.sub('‚Äô', '\\'', text)\n",
    "    # replace [] and {} with ()\n",
    "    #text = text.replace('[','(').replace(']',')').replace('{','(').replace('}',')')\n",
    "    text = re.sub('\\[','(', text)\n",
    "    text = re.sub('\\]',')', text)\n",
    "    text = re.sub('\\{','(', text)\n",
    "    text = re.sub('\\}',')', text)\n",
    "    # replace ? with itself and a whitespace preceding it\n",
    "    # ex. what's your name? (we want the word name and question mark to be separate tokens)\n",
    "    # text = re.sub('\\?', ' ?', text)\n",
    "    # creating a space between a word and the punctuation following it\n",
    "    # punctuation we're using: . , : ; ' ? ! + - * / = % $ @ & ( )\n",
    "    text = re.sub(\"([?.!,:;'?!+\\-*/=%$@&()])\", r\" \\1 \", text)\n",
    "    \n",
    "     # lower case the characters in the string\n",
    "    text = text.lower()\n",
    "    \n",
    "    # REMOVAL OF EXTRA WHITESPACES\n",
    "    # remove duplicated spaces\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # remove leading and trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a nice quote i read today : ' everything that you are going through is preparing you for what you asked for ' . @ hi % & = + - * /\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(\"A nice quote I read    today: ‚ÄúEverything that you are going through is preparing you for what you asked for‚Äù. @hi % & =+-*/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method prints a question-answer pair from the dataset, it will be helpful to give us a sense of what the clean_text function results in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_question_answer(df, index, cols):\n",
    "    print(f\"Question: ({index})\")\n",
    "    print(df.loc[index][cols[0]])\n",
    "    print(f\"Answer: ({index})\")\n",
    "    print(df.loc[index][cols[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before applying text preprocessing:\n",
      "Question: (102)\n",
      "What's 11 & 2?\n",
      "Answer: (102)\n",
      "The Cowboys\n",
      "Question: (200)\n",
      "What did the girlfriend say to her boyfriend that was bitten by a zombie?\n",
      "Answer: (200)\n",
      "You're dead to me\"\n",
      "Question: (88376)\n",
      "I think my husband is psychic! \"Honey, what do you think of this outfit\n",
      "Answer: (88376)\n",
      "\" {from other room} \"You look great!\"\n",
      "Question: (94351)\n",
      "{Thomas Edison prank call} Is your refrigerator running\n",
      "Answer: (94351)\n",
      " \"Yes..\" YOU'RE WELCOME! *click*\n"
     ]
    }
   ],
   "source": [
    "print(\"Before applying text preprocessing:\")\n",
    "print_question_answer(wordball, 102, ['Question', 'Answer'])\n",
    "print_question_answer(wordball, 200, ['Question', 'Answer'])\n",
    "print_question_answer(wordball, 88376, ['Question', 'Answer'])\n",
    "print_question_answer(wordball, 94351, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply text preprocessing (characters replacement, removal of unwanted characters, removal of extra whitespaces):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordball = wordball.applymap(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After applying text preprocessing:\n",
      "Question: (102)\n",
      "what ' s 11 & 2 ?\n",
      "Answer: (102)\n",
      "the cowboys\n",
      "Question: (200)\n",
      "what did the girlfriend say to her boyfriend that was bitten by a zombie ?\n",
      "Answer: (200)\n",
      "you ' re dead to me '\n",
      "Question: (88376)\n",
      "i think my husband is psychic ! ' honey , what do you think of this outfit\n",
      "Answer: (88376)\n",
      "' ( from other room ) ' you look great ! '\n",
      "Question: (94351)\n",
      "( thomas edison prank call ) is your refrigerator running\n",
      "Answer: (94351)\n",
      "' yes . . ' you ' re welcome ! * click *\n"
     ]
    }
   ],
   "source": [
    "print(\"After applying text preprocessing:\")\n",
    "print_question_answer(wordball, 102, ['Question', 'Answer'])\n",
    "print_question_answer(wordball, 200, ['Question', 'Answer'])\n",
    "print_question_answer(wordball, 88376, ['Question', 'Answer'])\n",
    "print_question_answer(wordball, 94351, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function applies some preprocessing operations on the data, concretely:\n",
    "\n",
    "Drops unecessary duplicate pairs (rows) but keep only one instance of all duplicates. (For example, if the dataset contains three duplicates of the same question-answer pair, then two of them would be removed and one kept.)\n",
    "Drops rows with empty question/answer. (These may appear because of the previous step or because they happen to be empty in the original dataset)\n",
    "Drops rows with more than 30 words in either the question or the answer or if the answer has less than two characters. (Note: this is a hyperparameter and you can try other values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, cols):\n",
    "    \"\"\"\n",
    "    This method preprocess data and does the following:\n",
    "    1. drops unecessary duplicate pairs.\n",
    "    2. drops rows with empty strings.\n",
    "    3. drops rows with more than 30 words in either the question or the answer, \n",
    "    or if the an answer has less than two characters.\n",
    "    Arguments:\n",
    "        data: a pandas dataframe.\n",
    "        cols: a Python list, representing names of columns for questions and answers. First item of the list should be the name \n",
    "        of the questions column and the second item should be the name of the column corresponding to answers.\n",
    "    Returns:\n",
    "        a pandas dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # (1) Remove unecessary duplicate pairs but keep only one instance of all duplicates.\n",
    "    print('Removing unecessary duplicate pairs:')\n",
    "    data_len_before = len(data) # len of data before removing duplicates\n",
    "    print(f\"# of examples before removing duplicates: {data_len_before}\")\n",
    "    # drop duplicates\n",
    "    data = data.drop_duplicates(keep='first')\n",
    "    data_len_after = len(data) # len of data after removing duplicates\n",
    "    print(f\"# of examples after removing duplicates: {data_len_after}\")\n",
    "    print(f\"# of removed duplicates: {data_len_before-data_len_after}\")\n",
    "    \n",
    "    \n",
    "    # (2) Drop rows with empty strings.\n",
    "    print('Removing empty string rows:')\n",
    "    if cols is None:\n",
    "        cols = list(data.columns)\n",
    "        \n",
    "    data_len_before = len(data) # len of data before removing empty strings\n",
    "    print(f\"# of examples before removing rows with empty question/answers: {data_len_before}\")\n",
    "    # I am going to use boolean masking to filter out rows with an empty question or answer\n",
    "    data = data[(data[cols[0]] != '') & (data[cols[1]] != '')]\n",
    "    # also, the following row results in the same as the above.\n",
    "    # data = data.query('Answer != \"\" and Question != \"\"')\n",
    "    data_len_after = len(data) # len of data after removing empty strings\n",
    "    print(f\"# of examples after removing with empty question/answers: {data_len_after}\")\n",
    "    print(f\"# of removed empty string rows: {data_len_before-data_len_after}\")\n",
    "    \n",
    "    \n",
    "    # (3) Drop rows with more than 30 words in either the question or the answer\n",
    "    # or if the an answer has less than two characters.\n",
    "    def accepted_length(qa_pair):\n",
    "        q_len = len(qa_pair[0].split(' '))\n",
    "        a_len = len(qa_pair[1].split(' '))\n",
    "        if (q_len <= 30) & ((a_len <= 30) & (len(qa_pair[1]) > 1)):\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    print('Removing rows with more than 30 words in either the question or the answer:')\n",
    "    data_len_before = len(data) # len of data before dropping those rows (30+ words)\n",
    "    print(f\"# of examples before removing rows with more than 30 words: {data_len_before}\")\n",
    "    # filter out rows with more than 30 words\n",
    "    accepted_mask = data.apply(accepted_length, axis=1)\n",
    "    data = data[accepted_mask]\n",
    "    data_len_after = len(data) # len of data after dropping those rows (50+ words)\n",
    "    print(f\"# of examples after removing rows with more than 30 words: {data_len_after}\")\n",
    "    print(f\"# of removed empty rows with more than 30 words: {data_len_before-data_len_after}\")\n",
    "    \n",
    "    print(\"Data preprocessing is done.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing unecessary duplicate pairs:\n",
      "# of examples before removing duplicates: 107234\n",
      "# of examples after removing duplicates: 107144\n",
      "# of removed duplicates: 90\n",
      "Removing empty string rows:\n",
      "# of examples before removing rows with empty question/answers: 107144\n",
      "# of examples after removing with empty question/answers: 107054\n",
      "# of removed empty string rows: 90\n",
      "Removing rows with more than 30 words in either the question or the answer:\n",
      "# of examples before removing rows with more than 30 words: 107054\n",
      "# of examples after removing rows with more than 30 words: 101712\n",
      "# of removed empty rows with more than 30 words: 5342\n",
      "Data preprocessing is done.\n"
     ]
    }
   ],
   "source": [
    "wordball = preprocess_data(wordball, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of question-answer pairs we have left in the Wordball dataset: 101712\n"
     ]
    }
   ],
   "source": [
    "print(f\"# of question-answer pairs we have left in the Wordball dataset: {len(wordball)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the characters after cleaning the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters used in the dataset: 83\n",
      "Digits: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
      "Alphabets: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '√ü', '√®', '√©', '√±', '√≥', '√∂', '√º']\n",
      "Special characters: [' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '\\\\', '^', '_', '`', '|', '~', '\\xa0', '¬°', '¬´', '¬ª', '¬ø', '\\u200b', '‚Äì', '‚Äî', '‚Äò', '‚Ä¶', '‚Ñ¢', '\\ufeff']\n"
     ]
    }
   ],
   "source": [
    "distinct_chars(wordball, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Dataset\n",
    "reddit /r/Jokes, here.\n",
    "\n",
    "This dataset consists of two files, namely:\n",
    "\n",
    "jokes_score_name_clean.csv: with 133,992 pairs.\n",
    "all_jokes.csv\n",
    "However, I'm not going to incorporate all_jokes.csv in the dataset because it's so messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_jokes = pd.read_csv(files_path + 'jokes_score_name_clean.csv', usecols=['q', 'a'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rename the columns to have them aligned with the previous dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_jokes.rename(columns={'q':'Question', 'a':'Answer'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I enjoy working in a slaughterhouse..</td>\n",
       "      <td>Everything is so cut and dry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you call a soldier who survives Mustar...</td>\n",
       "      <td>A seasoned veteran.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I really like white dwarf stars...</td>\n",
       "      <td>...My favorite is Peter Dinklage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Knock knock. Whose their?</td>\n",
       "      <td>The grammar police.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What breaks when you give it to a twelve year ...</td>\n",
       "      <td>Her hips.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0              I enjoy working in a slaughterhouse..   \n",
       "1  What do you call a soldier who survives Mustar...   \n",
       "2                 I really like white dwarf stars...   \n",
       "3                          Knock knock. Whose their?   \n",
       "4  What breaks when you give it to a twelve year ...   \n",
       "\n",
       "                               Answer  \n",
       "0       Everything is so cut and dry.  \n",
       "1                A seasoned veteran.   \n",
       "2  ...My favorite is Peter Dinklage.   \n",
       "3                 The grammar police.  \n",
       "4                          Her hips.   "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133328\n"
     ]
    }
   ],
   "source": [
    "print(len(reddit_jokes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters used in the dataset: 567\n",
      "Digits: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '¬≤', '¬≥', '¬π', '‚ÇÇ', '‚ÇÑ']\n",
      "Alphabets: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¬µ', '¬∫', '√Ñ', '√ë', '√ñ', '√ü', '√†', '√°', '√£', '√§', '√•', '√¶', '√ß', '√®', '√©', '√™', '√´', '√¨', '√≠', '√Æ', '√Ø', '√±', '√≤', '√≥', '√¥', '√µ', '√∂', '√∏', '√π', '√∫', '√ª', '√º', '√æ', 'ƒÅ', 'ƒì', 'ƒõ', 'ƒ±', '≈Ñ', '≈ç', '≈ì', '∆É', '∆Ü', '«é', '«ê', '«í', '«ö', '«ù', '…ê', '…ë', '…î', '…ô', '…ü', '…°', '…•', '…™', '…Ø', '…¥', '…π', '…æ', ' á', ' å', ' ç', ' é', ' è', ' ñ', ' ò', ' û', ' ü', ' ∞', ' ≤', ' ≥', ' ∑', ' ∏', 'Àà', 'À¢', 'Œî', 'Œ†', 'Œ£', 'ŒØ', 'Œ±', 'Œ∫', 'Œª', 'Œº', 'ŒΩ', 'œÄ', 'œÅ', 'œâ', 'œ±', '–ê', '–î', '–ö', '–¢', '–∞', '–µ', '–ª', '–º', '–æ', '—Ç', '—à', '—è', '‘Ä', '◊ê', '◊ë', '◊í', '◊î', '◊ï', '◊ñ', '◊ó', '◊ò', '◊ô', '◊ö', '◊õ', '◊ú', '◊ù', '◊ü', '◊†', '◊¢', '◊§', '◊¶', '◊ß', '◊®', '◊©', '◊™', '‡•ê', '‡≤†', '·¥Ä', '·¥Ñ', '·¥Ö', '·¥á', '·¥â', '·¥ç', '·¥è', '·¥ò', '·¥õ', '·¥ú', '·µÉ', '·µá', '·µà', '·µâ', '·µí', '·µñ', '·µó', '·µò', '·µõ', '·∂¶', '·∂´', '·∂∞', '·∏±', '·ªÖ', '„ÉÑ', '„ÉÆ', '‰∏Ä', '‰∏§', '‰∏™', '‰∏∫', '‰∏ª', '‰πà', '‰∫Ü', '‰∫∫', '‰ªÄ', '‰ªñ', '‰ΩÜ', '‰Ω†', 'ÂÅö', 'ÂÇ≤', 'ÂÑø', 'ÂÖ¥', 'ÂÜç', 'Âçñ', 'Âêë', 'ÂëÄ', 'Âë¢', 'Âí¶', 'Âí©', 'Âï≤', 'Âñ∫', 'Âú∞', 'Âùó', 'Â§©', 'Â•≥', 'Â•π', 'Â•Ω', 'Â¶à', 'Â≠ê', 'Â≠©', 'ÂØπ', 'Â∞è', 'Âπ≤', 'Â∫¶', 'Âæà', 'ÊÑü', 'Êàë', 'Êñã', 'Êò®', 'ÊòØ', 'ÊùØ', 'Êûó', 'Êûú', 'ÊµÆ', 'Áãó', 'Áî∑', 'ÁôΩ', 'ÁöÑ', 'Áúü', 'Á©∑', 'Á¨ë', 'Á≥ñ', 'Á∑ä', 'Áªô', 'ËÄÅ', 'Ë¶Å', 'ËØ¥', 'Ë∂£', 'ÈÇ£', 'Èí±', 'Èöª', 'È™Ñ', 'Ô¨Å', 'Ôæü']\n",
      "Special characters: ['\\x08', '\\t', '\\n', '\\r', '\\x19', '\\x1c', '\\x1d', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '\\x92', '\\x93', '\\x94', '\\x9d', '\\xa0', '¬°', '¬¢', '¬£', '¬•', '¬´', '\\xad', '¬Æ', '¬Ø', '¬∞', '¬¥', '¬∑', '¬ª', '¬æ', '¬ø', '√ó', 'Àô', 'Àö', 'Àú', 'Ãï', 'Ãñ', 'Ãó', 'Ãò', 'Ãô', 'Ãõ', 'Ãú', 'Ãù', 'Ãû', 'Ãü', 'Ã†', 'Ã°', 'Ã¢', 'Ã£', 'Ã§', 'Ã•', 'Ã¶', 'Ãß', 'Ã®', 'Ã©', 'Ã™', 'Ã´', 'Ã¨', 'Ã≠', 'ÃÆ', 'ÃØ', 'Ã∞', 'Ã±', 'Ã≤', 'Ã≥', 'Ã¥', 'Ãµ', 'Ã∂', 'Ã∑', 'Ã∏', 'Ãπ', 'Ã∫', 'Ãª', 'Ãº', 'ÕÄ', 'ÕÅ', 'ÕÖ', 'Õá', 'Õà', 'Õâ', 'Õç', 'Õé', 'Õè', 'Õì', 'Õî', 'Õï', 'Õñ', 'Õò', 'Õô', 'Õö', 'Õú', 'Õû', 'Õü', 'Õ†', 'Õ°', 'Õ¢', '“â', '\\u2000', '\\u2009', '\\u200b', '\\u200e', '\\u200f', '‚Äì', '‚Äî', '‚Äï', '‚Äò', '‚Äô', '‚Äö', '‚Äú', '‚Äù', '‚Äû', '‚Ä†', '‚Ä¢', '‚Ä¶', '\\u202a', '\\u202c', '‚Ä≤', '‚Ä≥', '‚ÄΩ', '‚ÅÑ', '\\u206a', '‚Ç¨', '‚Ç±', '‚Ñâ', '‚Ñ¢', '‚ÖÑ', '‚Üê', '‚Üë', '‚Üí', '‚Üì', '‚àÄ', '‚àÜ', '‚àë', '‚àí', '‚àö', '‚à´', '‚â§', '‚åê', '‚åò', '‚îÄ', '‚ï§', '‚ï¶', '‚ï≠', '‚ïÆ', '‚ñà', '‚ñ†', '‚ñ°', '‚óä', '‚òÄ', '‚òù', '‚òû', '‚òπ', '‚ò∫', '‚òº', '‚ô°', '‚ô•', '‚ô¶', '‚ô®', '‚ô™', '‚ô´', '‚ô≠', '‚ôª', '‚úÇ', '‚úà', '‚úå', '‚úè', '‚úì', '‚úî', '‚ù§', '‚üπ', '‚†Å', '‚†ä', '‚†ô', '‚†ù', '‚††', '‚¨Ö', '\\u3000', '„ÄÇ', '„Äå', '„Äç', 'Ô∏è', 'Ô∏ª', '\\ufeff', 'Ôºå', 'Ôºö', 'Ôºü', 'Ôø°', 'ÔøΩ', 'üÖ±', 'üáß', 'üá©', 'üá™', 'üá∑', 'üá∏', 'üá∫', 'üçû', 'üçª', 'üé§', 'üéµ', 'üé∂', 'üé∑', 'üé∫', 'üèÜ', 'üè¢', 'üêØ', 'üëç', 'üíÄ', 'üòÄ', 'üòÅ', 'üòÇ', 'üòÉ', 'üòÑ', 'üòÖ', 'üòÜ', 'üòà', 'üòâ', 'üòä', 'üòã', 'üòå', 'üòé', 'üòè', 'üòê', 'üòë', 'üòï', 'üòò', 'üòõ', 'üòú', 'üòù', 'üòü', 'üò°', 'üò¢', 'üò£', 'üò•', 'üò¶', 'üò®', 'üò©', 'üò´', 'üò≠', 'üòÆ', 'üò±', 'üò≥', 'üò∂', 'üôÇ', 'üôÑ', 'üôè', 'üöú', 'ü§ì', 'ü§î', 'ü§ó', 'ü§£', 'ü•Å', 'ü¶Ä', 'üßÄ']\n"
     ]
    }
   ],
   "source": [
    "distinct_chars(reddit_jokes, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_jokes = reddit_jokes.applymap(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reddit data has some special tags like [removed] or [deleted] (these two mean that the comment has been removed/deleted). Also, they're written in an inconsistent way, i.e. you may find the tag [removed] capitalized or lowercased.\n",
    "The next function will address reddit tags as follows:\n",
    "\n",
    "Drops rows with deleted, removed or censored tags.\n",
    "Replaces other tags found in text with a whitespace. (i.e. some comments have tags like [censored], [gaming], [long], [request] and [dirty] and we want to omit these tags from the text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reddit_tags(data, cols):\n",
    "    \"\"\"\n",
    "    This function removes reddit-related tags from the data and does the following:\n",
    "    1. drops rows with deleted, removed or censored tags.\n",
    "    2. replaces other tags found in text with a whitespace. \n",
    "    Arguments:\n",
    "        data: a pandas dataframe.\n",
    "        cols: a Python list, representing names of columns for questions and answers. First item of the list should be the name \n",
    "        of the questions column and the second item should be the name of the column corresponding to answers.\n",
    "    Returns:\n",
    "        a pandas dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    import re\n",
    "    \n",
    "    if cols is None:\n",
    "        cols = list(data.columns)\n",
    "    \n",
    "    # First, I'm going to lowercase all the text to address these tags \n",
    "    # however, I'm not going to alter the original dataframe because I don't want text to be lowercased.\n",
    "    data_copy = data.copy()\n",
    "    data_copy[cols[0]] = data_copy[cols[0]].str.lower()\n",
    "    data_copy[cols[1]] = data_copy[cols[1]].str.lower()\n",
    "    \n",
    "    # drop rows with deleted, removed or censored tags.\n",
    "    # qa_pair[0] is the question, qa_pair[1] is the answer\n",
    "    mask = data_copy.apply(lambda qa_pair: \n",
    "                           False if (qa_pair[0]=='[removed]') | (qa_pair[0]=='[deleted]') | (qa_pair[0]=='[censored]') |\n",
    "                           (qa_pair[1]=='[removed]') | (qa_pair[1]=='[deleted]') | (qa_pair[1]=='[censored]')\n",
    "                           else True, axis=1)\n",
    "    # drop the rows, notice we're using the mask to filter out those rows\n",
    "    # in the original dataframe 'data', because we don't need it anymore\n",
    "    data = data[mask]\n",
    "    print(f\"# of rows dropped with [deleted], [removed] or [censored] tags: {mask.sum()}\")\n",
    "    \n",
    "    # replaces other tags found in text with a whitespace. \n",
    "    def sub_tag(pair):\n",
    "        \"\"\"\n",
    "        This method substitute tags (square brackets with words inside) with whitespace.\n",
    "        Arguments:\n",
    "            pair: a Pandas Series, where the first item is the question and the second is the answer.\n",
    "        Returns:\n",
    "            pair: a Pandas Series.\n",
    "        \"\"\"\n",
    "        # \\[(.*?)\\] is a regex to recognize square brackets [] with anything in between\n",
    "        p=re.compile(\"\\[(.*?)\\]\")\n",
    "        pair[0] = re.sub(p, ' ', pair[0])\n",
    "        pair[1] = re.sub(p, ' ', pair[1])\n",
    "        \n",
    "        return pair\n",
    "    \n",
    "    # substitute tags with whitespaces.\n",
    "    data = data.apply(sub_tag, axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before addressing tags:\n",
      "Question: (1825)\n",
      "How do you piss off an entire community with one word?\n",
      "Answer: (1825)\n",
      "[Deleted]\n",
      "Question: (52906)\n",
      "[Corny] What does a highlighter say when it answers the phone?\n",
      "Answer: (52906)\n",
      "Yello?\n",
      "Question: (59924)\n",
      "How do you disappoint a redditor?\n",
      "Answer: (59924)\n",
      "[removed]\n",
      "Question: (1489)\n",
      "Everything men know about women\n",
      "Answer: (1489)\n",
      "[   ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Before addressing tags:\")\n",
    "print_question_answer(reddit_jokes, 1825, ['Question', 'Answer'])\n",
    "print_question_answer(reddit_jokes, 52906, ['Question', 'Answer'])\n",
    "print_question_answer(reddit_jokes, 59924, ['Question', 'Answer'])\n",
    "print_question_answer(reddit_jokes, 1489, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the following cell may take multiple seconds to finish.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of rows dropped with [deleted], [removed] or [censored] tags: 133117\n"
     ]
    }
   ],
   "source": [
    "reddit_jokes = clean_reddit_tags(reddit_jokes, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I enjoy working in a slaughterhouse..</td>\n",
       "      <td>Everything is so cut and dry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you call a soldier who survives Mustar...</td>\n",
       "      <td>A seasoned veteran.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I really like white dwarf stars...</td>\n",
       "      <td>...My favorite is Peter Dinklage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Knock knock. Whose their?</td>\n",
       "      <td>The grammar police.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What breaks when you give it to a twelve year ...</td>\n",
       "      <td>Her hips.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133323</th>\n",
       "      <td>Today a girl kissed me.</td>\n",
       "      <td>I wish I could post it in another subreddit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133324</th>\n",
       "      <td>The millennium is now legal.</td>\n",
       "      <td>Who wants to be the first person to fuck time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133325</th>\n",
       "      <td>I haven't   since last year.</td>\n",
       "      <td>(obligatory)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133326</th>\n",
       "      <td>A 17 year old male walks into a drug store...</td>\n",
       "      <td>A 17 year old male walks into a drug store. He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133327</th>\n",
       "      <td>Is this sub dead?</td>\n",
       "      <td>I haven‚Äôt seen any posts all year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>133117 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Question  \\\n",
       "0                   I enjoy working in a slaughterhouse..   \n",
       "1       What do you call a soldier who survives Mustar...   \n",
       "2                      I really like white dwarf stars...   \n",
       "3                               Knock knock. Whose their?   \n",
       "4       What breaks when you give it to a twelve year ...   \n",
       "...                                                   ...   \n",
       "133323                            Today a girl kissed me.   \n",
       "133324                       The millennium is now legal.   \n",
       "133325                       I haven't   since last year.   \n",
       "133326      A 17 year old male walks into a drug store...   \n",
       "133327                                  Is this sub dead?   \n",
       "\n",
       "                                                   Answer  \n",
       "0                           Everything is so cut and dry.  \n",
       "1                                    A seasoned veteran.   \n",
       "2                      ...My favorite is Peter Dinklage.   \n",
       "3                                     The grammar police.  \n",
       "4                                              Her hips.   \n",
       "...                                                   ...  \n",
       "133323       I wish I could post it in another subreddit.  \n",
       "133324  Who wants to be the first person to fuck time ...  \n",
       "133325                                       (obligatory)  \n",
       "133326  A 17 year old male walks into a drug store. He...  \n",
       "133327                  I haven‚Äôt seen any posts all year  \n",
       "\n",
       "[133117 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_jokes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After addressing tags:\n",
      "Question: (52906)\n",
      "  What does a highlighter say when it answers the phone?\n",
      "Answer: (52906)\n",
      "Yello?\n",
      "Question: (1489)\n",
      "Everything men know about women\n",
      "Answer: (1489)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(\"After addressing tags:\")\n",
    "# because rows with [removed], [deleted] and [censored] tags have been dropped\n",
    "# we're not going to print the rows (index=1825, index=59924) since they contain \n",
    "# those tags, or we're going to have a KeyError\n",
    "print_question_answer(reddit_jokes, 52906, ['Question', 'Answer'])\n",
    "print_question_answer(reddit_jokes, 1489, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: notice the question whose index is 52906, has some leading whitespaces. That's because it had the [Corny] tag and the function replaced it with whitespaces. Also, the question whose index is 1489 has an empty answer and that's because of the fact that the original answer just square brackets with some whitespaces in between. We're going to address all of that next!\n",
    "\n",
    "Now, let's apply the clean_text function on the reddit data.\n",
    "Remember: the clean_text function replaces some characters with others, removes unwanted characters and gets rid of extra whitespaces from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_jokes = reddit_jokes.applymap(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: (52906)\n",
      "what does a highlighter say when it answers the phone ?\n",
      "Answer: (52906)\n",
      "yello ?\n",
      "Question: (1489)\n",
      "everything men know about women\n",
      "Answer: (1489)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_question_answer(reddit_jokes, 52906, ['Question', 'Answer'])\n",
    "print_question_answer(reddit_jokes, 1489, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good!\n",
    "Now, let's apply the preprocess_data function on the data.\n",
    "Remember: the preprocess_data function applies the following preprocessing operations:\n",
    "\n",
    "Drops unecessary duplicate pairs (rows) but keep only one instance of all duplicates. (For example, if the dataset contains three duplicates of the same question-answer pair, then two of them would be removed and one kept.)\n",
    "Drops rows with empty question/answer. (These may appear because of the previous step or because they happen to be empty in the original dataset)\n",
    "Drops rows with more than 30 words in either the question or the answer or if the an answer has less than two characters. (Note: this is a hyperparameter and you can try other values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing unecessary duplicate pairs:\n",
      "# of examples before removing duplicates: 133117\n",
      "# of examples after removing duplicates: 128510\n",
      "# of removed duplicates: 4607\n",
      "Removing empty string rows:\n",
      "# of examples before removing rows with empty question/answers: 128510\n",
      "# of examples after removing with empty question/answers: 128428\n",
      "# of removed empty string rows: 82\n",
      "Removing rows with more than 30 words in either the question or the answer:\n",
      "# of examples before removing rows with more than 30 words: 128428\n",
      "# of examples after removing rows with more than 30 words: 89016\n",
      "# of removed empty rows with more than 30 words: 39412\n",
      "Data preprocessing is done.\n"
     ]
    }
   ],
   "source": [
    "reddit_jokes = preprocess_data(reddit_jokes, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question answer pairs in the reddit /r/Jokes dataset: 89016\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of question answer pairs in the reddit /r/Jokes dataset: {len(reddit_jokes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters used in the dataset: 280\n",
      "Digits: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '¬≤', '¬≥', '‚ÇÇ', '‚ÇÑ']\n",
      "Alphabets: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¬µ', '¬∫', '√ü', '√†', '√°', '√§', '√•', '√¶', '√®', '√©', '√´', '√≠', '√Ø', '√±', '√≥', '√µ', '√∂', '√∏', '√∫', '√ª', '√º', '√æ', 'ƒ±', '≈ì', '∆É', '«ù', '…ê', '…î', '…ô', '…ü', '…•', '…™', '…Ø', '…¥', '…π', '…æ', ' á', ' å', ' ç', ' é', ' è', ' ñ', ' ò', ' û', ' ü', ' ∞', ' ≤', ' ≥', ' ∑', ' ∏', 'Àà', 'À¢', 'Œ¥', 'Œº', 'œÄ', 'œÅ', 'œÉ', 'œ±', '‘Å', '◊ü', '◊§', '‡•ê', '‡≤†', '·¥Ä', '·¥Ñ', '·¥Ö', '·¥á', '·¥â', '·¥ç', '·¥è', '·¥ò', '·¥õ', '·¥ú', '·µÉ', '·µá', '·µà', '·µâ', '·µí', '·µñ', '·µó', '·µò', '·µõ', '·∂¶', '·∂´', '·∂∞', '·ªÖ', '„ÉÑ', '„ÉÆ', 'Ôæü']\n",
      "Special characters: ['\\t', '\\n', '\\r', ' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '\\\\', '^', '_', '`', '|', '~', '\\xa0', '¬°', '¬¢', '¬£', '¬´', '\\xad', '¬Æ', '¬Ø', '¬∞', '¬¥', '¬∑', '¬ª', '¬æ', '¬ø', '√ó', 'Àô', 'Àö', 'Õú', 'Õ°', '\\u2000', '\\u200b', '\\u200e', '‚Äì', '‚Äî', '‚Äò', '‚Ä¢', '‚Ä¶', '\\u202a', '\\u202c', '‚Ä≥', '‚ÄΩ', '\\u206a', '‚Ç¨', '‚Ñâ', '‚Ñ¢', '‚ÖÑ', '‚Üê', '‚Üë', '‚Üí', '‚Üì', '‚àÄ', '‚àë', '‚àí', '‚àö', '‚à´', '‚åê', '‚îÄ', '‚ï§', '‚ï¶', '‚ñà', '‚ñ†', '‚ñ°', '‚òÄ', '‚òû', '‚òπ', '‚ò∫', '‚òº', '‚ô™', '‚ô´', '‚ô≠', '‚ôª', '‚úà', '‚úì', '‚ù§', '‚†Å', '‚†ä', '‚†ô', '‚†ù', '‚††', '‚¨Ö', 'Ô∏è', 'Ô∏ª', '\\ufeff', 'Ôºö', 'Ôºü', 'üÖ±', 'üáß', 'üá©', 'üá™', 'üá∑', 'üçû', 'üçª', 'üé§', 'üé∂', 'üè¢', 'üêØ', 'üëç', 'üòÄ', 'üòÇ', 'üòÉ', 'üòÜ', 'üòà', 'üòâ', 'üòä', 'üòã', 'üòå', 'üòé', 'üòè', 'üòê', 'üòë', 'üòï', 'üòò', 'üòú', 'üòù', 'üò°', 'üò¢', 'üò£', 'üò•', 'üò©', 'üò≠', 'üò≥', 'üò∂', 'üôÇ', 'üôÑ', 'üôè', 'üöú', 'ü§î', 'ü•Å', 'ü¶Ä', 'üßÄ']\n"
     ]
    }
   ],
   "source": [
    "distinct_chars(reddit_jokes, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Dataset\n",
    "Question-Answer Jokes, here.\n",
    "\n",
    "This dataset consists of one file, namely:\n",
    "\n",
    "jokes_score_name_clean.csv: with 38,269 pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Did you hear about the Native American man tha...</td>\n",
       "      <td>He nearly drown in his own tea pee.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's the best anti diarrheal prescription?</td>\n",
       "      <td>Mycheexarphlexin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What do you call a person who is outside a doo...</td>\n",
       "      <td>Matt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Which Star Trek character is a member of the m...</td>\n",
       "      <td>Jean-Luc Pickacard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's the difference between a bullet and a h...</td>\n",
       "      <td>A bullet doesn't miss Harambe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Did you hear about the Native American man tha...   \n",
       "1       What's the best anti diarrheal prescription?   \n",
       "2  What do you call a person who is outside a doo...   \n",
       "3  Which Star Trek character is a member of the m...   \n",
       "4  What's the difference between a bullet and a h...   \n",
       "\n",
       "                                Answer  \n",
       "0  He nearly drown in his own tea pee.  \n",
       "1                     Mycheexarphlexin  \n",
       "2                                 Matt  \n",
       "3                   Jean-Luc Pickacard  \n",
       "4        A bullet doesn't miss Harambe  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_jokes = pd.read_csv(files_path + 'jokes.csv', usecols=['Question', 'Answer'])\n",
    "qa_jokes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters used in the dataset: 237\n",
      "Digits: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '¬≥', '‡±™', '‚ÇÑ']\n",
      "Alphabets: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '√à', '√â', '√ë', '√ü', '√°', '√§', '√•', '√¶', '√®', '√©', '√™', '√¨', '√≠', '√Æ', '√Ø', '√±', '√≤', '√≥', '√µ', '√∂', '√∏', '√π', '√∫', '√ª', '√º', 'ƒê', 'ƒ±', '≈ç', '≈ì', ' É', ' Ö', ' ñ', 'Œë', 'Œú', 'Œ©', 'Œ¨', 'Œµ', 'Œ∂', 'Œ∑', 'Œ∏', 'Œ∫', 'Œº', 'œÄ', 'œÅ', 'œÇ', '–°', '–±', '–µ', '–∏', '–Ω', '—Ä', '—Ç', '—å', '‡•ê', '‡≤†', '·ª©', '„Å•', '„ÉÑ', '‰∏Å', '‰∫å', 'Âñ≤', 'Â™Ω', 'Â¥á', 'Â∏∏', 'Ê∏Ö', 'ËÉñ', 'Ëë£', 'ÈÄô', 'È∫º', 'Îπµ']\n",
      "Special characters: [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', '\\xa0', '¬°', '¬£', '¬§', '¬©', '¬´', '¬¨', '\\xad', '¬Æ', '¬Ø', '¬∞', '¬¥', '¬∑', '¬ª', '¬ø', '√ó', 'Ã®', 'Ã∏', 'Õú', 'Õ°', '\\u200a', '\\u200b', '\\u200e', '‚Äì', '‚Äî', '‚Äò', '‚Äô', '‚Äú', '‚Äù', '‚Ä¢', '‚Ä¶', '\\u202a', '‚Ç¨', '‚Ñ¢', '‚àí', '‚àö', '‚àû', '‚à´', '‚â†', '‚åê', '‚îÄ', '‚ï§', '‚ï¶', '‚ñ†', '‚óî', '‚ô™', '‚ö°', '‚úà', '‚úè', '‚ûï', 'Ô∏è', 'Ô∏ª', '\\ufeff', 'Ôºå', 'üé∫', 'üè¢', 'üëå', 'üëç', 'üí©', 'üòÄ', 'üòÇ', 'üòÉ', 'üòÜ', 'üòè', 'üòî', 'üòú', 'üò≥', 'üôá', 'ü§ò']\n"
     ]
    }
   ],
   "source": [
    "distinct_chars(qa_jokes, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "If you look at some examples in the dataset, you notice that some examples has 'Q:' at beginning of the question and 'A:' at the beginning of the answer, so we need to get rid of these prefixes because they don't convey useful information.\n",
    "You also notice some examples where both 'Q:' and 'A:' are found in either the question or the answer, although I'm not going to omit these because they probably convey information and are part of the answer. However, some of them have 'Q:' in the question and 'Q: question A: answer' where the question in the answer is the same question, so we need to fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_qa_prefixes(data, cols):\n",
    "    \"\"\"\n",
    "    This function removes special prefixes ('Q:' and 'A:') found in the data.\n",
    "    i.e. input=\"Q: how's your day?\" --> output=\" how's your day?\"\n",
    "    Arguments:\n",
    "        data: a pandas dataframe.\n",
    "        cols: a Python list, representing names of columns for questions and answers. First item of the list should be the name \n",
    "        of the questions column and the second item should be the name of the column corresponding to answers.\n",
    "    Returns:\n",
    "        a pandas dataframe.\n",
    "    \"\"\"\n",
    "    def removes_prefixes(pair):\n",
    "        \"\"\"\n",
    "        This function removes prefixes ('Q:' and 'A:') from the question and answer.\n",
    "        Examples:\n",
    "        Input: qusetion=\"Q: what is your favorite Space movie?\", answer='A: Interstellar!'\n",
    "        Output: qusetion=' what is your favorite Space movie?', answer=' Interstellar!'\n",
    "        Input: question=\"Q: how\\'s your day?\", answer='Q: how\\'s your day? A: good, thanks.'\n",
    "        Output: qusetion=\" how's your day?\", answer='good, thanks.'\n",
    "        Input: qusetion='How old are you?', answer='old enough'\n",
    "        Output: qusetion='How old are you?', answer='old enough'\n",
    "        Arguments:\n",
    "            pair: a Pandas Series, where the first item is the question and the second is the answer.\n",
    "        Returns:\n",
    "            pair: a Pandas Series.\n",
    "        \"\"\"\n",
    "        # pair[0] corresponds to the question\n",
    "        # pair[1] corresponds to the answer\n",
    "        # if the question contains 'Q:' and the answer contains 'A:' but doesn't contain 'Q:'\n",
    "        if ('Q:' in pair[0]) and ('A:' in pair[1]) and ('Q:' not in pair[1]):\n",
    "            pair[0] = pair[0].replace('Q:','')\n",
    "            pair[1] = pair[1].replace('A:','')\n",
    "        # if the answer contains both 'Q:' and 'A:'\n",
    "        elif ('A:' in pair[1]) and ('Q:' in pair[1]):\n",
    "            pair[0] = pair[0].replace('Q:','')\n",
    "            # now we should check if the text between 'Q:' and 'A:' is the same text in the question (pair[0])\n",
    "            # because if they are, this means that the question is repeated in the answer and we should address that.\n",
    "            q_start = pair[1].find('Q:') + 2 # index of the start of the text that we want to extract\n",
    "            q_end = pair[1].find('A:') # index of the end of the text that we want to extract\n",
    "            q_txt = pair[1][q_start:q_end].strip()\n",
    "            # if the question is repeated in the answer\n",
    "            if q_txt == pair[0].strip():\n",
    "                # in case the question is repeated in the answer, removes it from the answer\n",
    "                pair[1] = pair[1][q_end+2:].strip()\n",
    "            \n",
    "        return pair\n",
    "        \n",
    "    return data.apply(removes_prefixes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removing unnecessary prefixes:\n",
      "Question: (44)\n",
      "Q: What did the left leg say to the right leg?\n",
      "Answer: (44)\n",
      "A: That one in the middle thinks he's hard.\n",
      "Question: (22)\n",
      "Why does Santa have three gardens?\n",
      "Answer: (22)\n",
      "Q: Why does Santa have three gardens? A: So he can \"hoe, hoe, hoe.\"\n",
      "Question: (31867)\n",
      "What is your favorite joke about women?\n",
      "Answer: (31867)\n",
      "Q: Why don't women wear watches? A: Because there is a clock on the stove.\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removing unnecessary prefixes:\")\n",
    "print_question_answer(qa_jokes, 44, ['Question', 'Answer'])\n",
    "print_question_answer(qa_jokes, 22, ['Question', 'Answer'])\n",
    "print_question_answer(qa_jokes, 31867, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_jokes = clean_qa_prefixes(qa_jokes, ['Question', 'Answer'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing unnecessary prefixes:\n",
      "Question: (44)\n",
      " What did the left leg say to the right leg?\n",
      "Answer: (44)\n",
      " That one in the middle thinks he's hard.\n",
      "Question: (22)\n",
      "Why does Santa have three gardens?\n",
      "Answer: (22)\n",
      "So he can \"hoe, hoe, hoe.\"\n",
      "Question: (31867)\n",
      "What is your favorite joke about women?\n",
      "Answer: (31867)\n",
      "Q: Why don't women wear watches? A: Because there is a clock on the stove.\n"
     ]
    }
   ],
   "source": [
    "print(\"After removing unnecessary prefixes:\")\n",
    "print_question_answer(qa_jokes, 44, ['Question', 'Answer'])\n",
    "print_question_answer(qa_jokes, 22, ['Question', 'Answer'])\n",
    "print_question_answer(qa_jokes, 31867, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the third example both 'Q:' and 'A:' are part of the answer and conveys information.\n",
    "\n",
    "Now, let's apply the clean_text function on the Question-Answer Jokes data.\n",
    "Remember: the clean_text function replaces some characters with others, removes unwanted characters and gets rid of extra whitespaces from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_jokes = qa_jokes.applymap(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply the preprocess_data function on the data.\n",
    "Remember: the preprocess_data function applies the following preprocessing operations:\n",
    "\n",
    "   1. Drops unnecessary duplicate pairs (rows) but keep only one instance of all duplicates. (For example, if the dataset contains three duplicates of the same question-answer pair, then two of them would be removed and one kept.)\n",
    "   2. Drops rows with an empty question/answer. (These may appear because of the previous step or because they happen to be empty in the original dataset)\n",
    "   3. Drops rows with more than 30 words in either the question or the answer or if the an answer has less than two characters. (Note: this is a hyperparameter and you can try other values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing unecessary duplicate pairs:\n",
      "# of examples before removing duplicates: 38269\n",
      "# of examples after removing duplicates: 38189\n",
      "# of removed duplicates: 80\n",
      "Removing empty string rows:\n",
      "# of examples before removing rows with empty question/answers: 38189\n",
      "# of examples after removing with empty question/answers: 38174\n",
      "# of removed empty string rows: 15\n",
      "Removing rows with more than 30 words in either the question or the answer:\n",
      "# of examples before removing rows with more than 30 words: 38174\n",
      "# of examples after removing rows with more than 30 words: 37092\n",
      "# of removed empty rows with more than 30 words: 1082\n",
      "Data preprocessing is done.\n"
     ]
    }
   ],
   "source": [
    "qa_jokes = preprocess_data(qa_jokes, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question-answer pairs in the Question-Answer Jokes dataset: 37092\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of question-answer pairs in the Question-Answer Jokes dataset: {len(qa_jokes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters used in the dataset: 193\n",
      "Digits: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '¬≥', '‡±™', '‚ÇÑ']\n",
      "Alphabets: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '√ü', '√°', '√§', '√•', '√¶', '√®', '√©', '√™', '√¨', '√≠', '√Æ', '√Ø', '√±', '√≤', '√≥', '√µ', '√∂', '√∏', '√π', '√∫', '√ª', '√º', 'ƒë', 'ƒ±', '≈ç', '≈ì', ' É', ' Ö', ' ñ', 'Œ¨', 'Œ±', 'Œµ', 'Œ∂', 'Œ∑', 'Œ∏', 'Œ∫', 'Œº', 'œÄ', 'œÅ', 'œÇ', 'œâ', '–±', '–µ', '–∏', '–Ω', '—Ä', '—Å', '—Ç', '—å', '‡•ê', '‡≤†', '·ª©', '„Å•', '„ÉÑ', '‰∏Å', 'Âñ≤', 'Â™Ω', 'Â¥á', 'Â∏∏', 'Ê∏Ö', 'ËÉñ', 'Ëë£', 'ÈÄô', 'È∫º', 'Îπµ']\n",
      "Special characters: [' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '\\\\', '^', '_', '`', '|', '~', '\\xa0', '¬°', '¬£', '¬©', '¬´', '¬¨', '\\xad', '¬Æ', '¬Ø', '¬∞', '¬¥', '¬∑', '¬ª', '¬ø', '√ó', 'Ã®', 'Ã∏', 'Õú', 'Õ°', '\\u200a', '\\u200b', '\\u200e', '‚Äì', '‚Äî', '‚Äò', '‚Ä¢', '‚Ä¶', '\\u202a', '‚Ç¨', '‚Ñ¢', '‚àö', '‚àû', '‚à´', '‚åê', '‚îÄ', '‚ï§', '‚ï¶', '‚ñ†', '‚óî', '‚ô™', '‚ö°', '‚úà', '‚úè', '‚ûï', 'Ô∏è', 'Ô∏ª', '\\ufeff', 'üè¢', 'üëå', 'üëç', 'üí©', 'üòÄ', 'üòÇ', 'üòÉ', 'üòÜ', 'üòè', 'üòî', 'üòú', 'üò≥', 'üôá', 'ü§ò']\n"
     ]
    }
   ],
   "source": [
    "distinct_chars(qa_jokes, ['Question', 'Answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it together\n",
    "Let's concatenate all the data we have to create our final dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what ' s the best anti diarrheal prescription ?</td>\n",
       "      <td>mycheexarphlexin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what do you call a person who is outside a doo...</td>\n",
       "      <td>matt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which star trek character is a member of the m...</td>\n",
       "      <td>jean - luc pickacard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what ' s the difference between a bullet and a...</td>\n",
       "      <td>a bullet doesn ' t miss harambe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why was the ethiopian baby crying ?</td>\n",
       "      <td>he was having a mid - life crisis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0    what ' s the best anti diarrheal prescription ?   \n",
       "1  what do you call a person who is outside a doo...   \n",
       "2  which star trek character is a member of the m...   \n",
       "3  what ' s the difference between a bullet and a...   \n",
       "4                why was the ethiopian baby crying ?   \n",
       "\n",
       "                              Answer  \n",
       "0                   mycheexarphlexin  \n",
       "1                               matt  \n",
       "2               jean - luc pickacard  \n",
       "3    a bullet doesn ' t miss harambe  \n",
       "4  he was having a mid - life crisis  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([wordball, reddit_jokes, qa_jokes], ignore_index=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question-answer pairs in the dataset: 227820\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of question-answer pairs in the dataset: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be duplicate examples in the data so let's drop them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of examples before removing duplicates: 227820\n",
      "# of examples after removing duplicates: 176980\n",
      "# of removed duplicates: 50840\n"
     ]
    }
   ],
   "source": [
    "data_len_before = len(dataset) # len of data before removing duplicates\n",
    "print(f\"# of examples before removing duplicates: {data_len_before}\")\n",
    "# drop duplicates\n",
    "dataset = dataset.drop_duplicates(keep='first')\n",
    "data_len_after = len(dataset) # len of data after removing duplicates\n",
    "print(f\"# of examples after removing duplicates: {data_len_after}\")\n",
    "print(f\"# of removed duplicates: {data_len_before-data_len_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop rows with NaN values if there's any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what ' s the best anti diarrheal prescription ?</td>\n",
       "      <td>mycheexarphlexin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what do you call a person who is outside a doo...</td>\n",
       "      <td>matt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which star trek character is a member of the m...</td>\n",
       "      <td>jean - luc pickacard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what ' s the difference between a bullet and a...</td>\n",
       "      <td>a bullet doesn ' t miss harambe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>why was the ethiopian baby crying ?</td>\n",
       "      <td>he was having a mid - life crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227800</th>\n",
       "      <td>how many surrealists does it take to change a ...</td>\n",
       "      <td>fish .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227805</th>\n",
       "      <td>here ' s a joke just for reddit : how many nar...</td>\n",
       "      <td>bacon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227807</th>\n",
       "      <td>what do you get when you combine a comedian an...</td>\n",
       "      <td>a brofl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227815</th>\n",
       "      <td>q : why did the pacifist / b / tard try to cal...</td>\n",
       "      <td>he did it for the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227816</th>\n",
       "      <td>why can ' t obama poke fun at himself ?</td>\n",
       "      <td>because that would be racist .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176980 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Question  \\\n",
       "0         what ' s the best anti diarrheal prescription ?   \n",
       "1       what do you call a person who is outside a doo...   \n",
       "2       which star trek character is a member of the m...   \n",
       "3       what ' s the difference between a bullet and a...   \n",
       "4                     why was the ethiopian baby crying ?   \n",
       "...                                                   ...   \n",
       "227800  how many surrealists does it take to change a ...   \n",
       "227805  here ' s a joke just for reddit : how many nar...   \n",
       "227807  what do you get when you combine a comedian an...   \n",
       "227815  q : why did the pacifist / b / tard try to cal...   \n",
       "227816            why can ' t obama poke fun at himself ?   \n",
       "\n",
       "                                   Answer  \n",
       "0                        mycheexarphlexin  \n",
       "1                                    matt  \n",
       "2                    jean - luc pickacard  \n",
       "3         a bullet doesn ' t miss harambe  \n",
       "4       he was having a mid - life crisis  \n",
       "...                                   ...  \n",
       "227800                             fish .  \n",
       "227805                              bacon  \n",
       "227807                            a brofl  \n",
       "227815                  he did it for the  \n",
       "227816     because that would be racist .  \n",
       "\n",
       "[176980 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that all our cells are of the same type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of question-answer pairs in the dataset: 176980\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of question-answer pairs in the dataset: {len(dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct characters used in the dataset: 335\n",
      "Digits: ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '¬≤', '¬≥', '‡±™', '‚ÇÇ', '‚ÇÑ']\n",
      "Alphabets: ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¬µ', '¬∫', '√ü', '√†', '√°', '√§', '√•', '√¶', '√®', '√©', '√™', '√´', '√¨', '√≠', '√Æ', '√Ø', '√±', '√≤', '√≥', '√µ', '√∂', '√∏', '√π', '√∫', '√ª', '√º', '√æ', 'ƒë', 'ƒ±', '≈ç', '≈ì', '∆É', '«ù', '…ê', '…î', '…ô', '…ü', '…•', '…™', '…Ø', '…¥', '…π', '…æ', ' É', ' Ö', ' á', ' å', ' ç', ' é', ' è', ' ñ', ' ò', ' û', ' ü', ' ∞', ' ≤', ' ≥', ' ∑', ' ∏', 'Àà', 'À¢', 'Œ¨', 'Œ±', 'Œ¥', 'Œµ', 'Œ∂', 'Œ∑', 'Œ∏', 'Œ∫', 'Œº', 'œÄ', 'œÅ', 'œÇ', 'œÉ', 'œâ', 'œ±', '–±', '–µ', '–∏', '–Ω', '—Ä', '—Å', '—Ç', '—å', '‘Å', '◊ü', '◊§', '‡•ê', '‡≤†', '·¥Ä', '·¥Ñ', '·¥Ö', '·¥á', '·¥â', '·¥ç', '·¥è', '·¥ò', '·¥õ', '·¥ú', '·µÉ', '·µá', '·µà', '·µâ', '·µí', '·µñ', '·µó', '·µò', '·µõ', '·∂¶', '·∂´', '·∂∞', '·ªÖ', '·ª©', '„Å•', '„ÉÑ', '„ÉÆ', '‰∏Å', 'Âñ≤', 'Â™Ω', 'Â¥á', 'Â∏∏', 'Ê∏Ö', 'ËÉñ', 'Ëë£', 'ÈÄô', 'È∫º', 'Îπµ', 'Ôæü']\n",
      "Special characters: ['\\t', '\\n', '\\r', ' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '\\\\', '^', '_', '`', '|', '~', '\\xa0', '¬°', '¬¢', '¬£', '¬©', '¬´', '¬¨', '\\xad', '¬Æ', '¬Ø', '¬∞', '¬¥', '¬∑', '¬ª', '¬æ', '¬ø', '√ó', 'Àô', 'Àö', 'Ã®', 'Ã∏', 'Õú', 'Õ°', '\\u2000', '\\u200a', '\\u200b', '\\u200e', '‚Äì', '‚Äî', '‚Äò', '‚Ä¢', '‚Ä¶', '\\u202a', '\\u202c', '‚Ä≥', '‚ÄΩ', '\\u206a', '‚Ç¨', '‚Ñâ', '‚Ñ¢', '‚ÖÑ', '‚Üê', '‚Üë', '‚Üí', '‚Üì', '‚àÄ', '‚àë', '‚àí', '‚àö', '‚àû', '‚à´', '‚åê', '‚îÄ', '‚ï§', '‚ï¶', '‚ñà', '‚ñ†', '‚ñ°', '‚óî', '‚òÄ', '‚òû', '‚òπ', '‚ò∫', '‚òº', '‚ô™', '‚ô´', '‚ô≠', '‚ôª', '‚ö°', '‚úà', '‚úè', '‚úì', '‚ù§', '‚ûï', '‚†Å', '‚†ä', '‚†ô', '‚†ù', '‚††', '‚¨Ö', 'Ô∏è', 'Ô∏ª', '\\ufeff', 'Ôºö', 'Ôºü', 'üÖ±', 'üáß', 'üá©', 'üá™', 'üá∑', 'üçû', 'üçª', 'üé§', 'üé∂', 'üè¢', 'üêØ', 'üëå', 'üëç', 'üí©', 'üòÄ', 'üòÇ', 'üòÉ', 'üòÜ', 'üòà', 'üòâ', 'üòä', 'üòã', 'üòå', 'üòé', 'üòè', 'üòê', 'üòë', 'üòî', 'üòï', 'üòò', 'üòú', 'üòù', 'üò°', 'üò¢', 'üò£', 'üò•', 'üò©', 'üò≠', 'üò≥', 'üò∂', 'üôÇ', 'üôÑ', 'üôá', 'üôè', 'üöú', 'ü§î', 'ü§ò', 'ü•Å', 'ü¶Ä', 'üßÄ']\n"
     ]
    }
   ],
   "source": [
    "distinct_chars(dataset, ['Question', 'Answer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's save the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(files_path + '/dataset.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good! we can use this dataset to develop any kind of NLP/NLU model.\n",
    "\n",
    "\n",
    "# Further reading\n",
    "\n",
    "\n",
    "1.Steps for a Developer to Learn Apache Spark‚Ñ¢ with Delta Lake [link](https://databricks.com/p/ebook/learn-apache-spark-with-delta-lake?utm_medium=cpc&utm_source=bing&utm_campaign=392642117&utm_offer=learn-apache-spark-with-delta-lake&utm_content=ebook&utm_term=%2Bspark&msclkid=e89c97e97c3b11a24c5dc85a6642b6bd).\n",
    "\n",
    "2.MLlib: Machine Learning in Apache Spark [link](https://jmlr.org/papers/volume17/15-237/15-237.pdf).\n",
    " \n",
    "3.Hands-On Deep Learning with Apache Spark [link](https://lib-ebooks.com/hands-on-deep-learning-with-apache-spark/)\n",
    " \n",
    " \n",
    " \n",
    "# Summary\n",
    "In this tutorial, you discovered how to process and prepare unstructure data(text) using NLTK re library. focused on a Python API of Jupyter notebook. \n",
    "\n",
    "Specifically, you learned:\n",
    "\n",
    "* How to import Data into jupyter notebook.\n",
    "* How to define classes to deal with different situation in the dataset.\n",
    "* How to concatenate different dataset.\n",
    "* How to save dataset.\n",
    "\n",
    "\n",
    "## Next Step\n",
    "\n",
    "There is still much room to improve like try to do same job using spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
